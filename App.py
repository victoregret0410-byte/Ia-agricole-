import os
import io
import requests
import streamlit as st
from groq import Groq
import pandas as pd
import pdfplumber

# =========================================================
# CONFIG GLOBALE
# =========================================================

APP_NAME = "üí¨ IA Conseiller ‚Äì Chat s√©rieux"
APP_VERSION = "2.0.0"

st.set_page_config(
    page_title=APP_NAME,
    page_icon="üí¨",
    layout="centered",  # une seule colonne, comme ChatGPT mobile
)

# --------- Client Groq (cl√© √† mettre dans les secrets Streamlit : GROQ_API_KEY) ----------
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY else None


# =========================================================
# STYLE GLOBAL ‚Äì sobre, propre, type ChatGPT
# =========================================================

st.markdown(
    """
    <style>
    html, body, [class*="css"] {
        font-family: -apple-system, BlinkMacSystemFont, system-ui, sans-serif;
        background-color: #ffffff;
    }
    .main {
        background-color: #ffffff;
    }
    .block-container {
        padding-top: 1.2rem;
        padding-bottom: 3rem;
        max-width: 780px;
    }
    .stButton>button, .stDownloadButton>button {
        border-radius: 999px;
        padding: 0.35rem 1.2rem;
        font-weight: 600;
    }
    .app-title {
        font-size: 1.8rem;
        font-weight: 700;
        margin-bottom: 0.2rem;
    }
    .app-subtitle {
        color: #666;
        font-size: 0.85rem;
        margin-bottom: 1rem;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# =========================================================
# MODES, LANGUES, MOD√àLES
# =========================================================

LANG_OPTIONS = {
    "Fran√ßais": "fr",
    "English": "en",
    "Espa√±ol": "es",
    "Deutsch": "de",
}

MODEL_OPTIONS = {
    "Groq ‚Äì pr√©cis & rapide (LLaMA 3.1 70B)": {
        "id": model="llama-3.2-90b-vision-preview",
        "temp": 0.25,
        "max_tokens": 800,
    },
    "Groq ‚Äì l√©ger (LLaMA 3.2 3B)": {
        "id": "llama-3.2-3b-instruct",
        "temp": 0.35,
        "max_tokens": 600,
    },
}

MODE_PROMPTS = {
    "Chat g√©n√©ral": """
Tu es une IA de conversation s√©rieuse, calme, jamais offensante.
Tu peux parler de tous les sujets, de fa√ßon claire et logique.
Quand tu ne sais pas, tu le dis franchement.
""",
    "Conseiller agricole": """
Tu es un conseiller agricole IA. Tu aides √† :
- raisonner les cultures et rotations,
- r√©fl√©chir aux charges, marges, organisation de la ferme,
- am√©liorer l'√©levage (bovins, ovins, caprins, volailles) sans donner de conseils v√©t√©rinaires dangereux,
- gagner du temps sur les papiers (tableaux, id√©es de factures, synth√®ses).
Tu expliques comme un coll√®gue agriculteur exp√©riment√©, sans jugement.
""",
    "Gestion & compta": """
Tu aides l'utilisateur √† comprendre ses chiffres agricoles :
produits, charges, marges, EBE, remboursement des annuit√©s.
Tu d√©tailles les calculs √©tape par √©tape. Tu restes prudent :
tu ne remplaces pas un expert-comptable.
""",
    "Documents & administration": """
Tu aides √† r√©diger des textes s√©rieux : mails, lettres, comptes rendus,
proc√©dures, fiches de poste. Tu peux proposer des structures de tableaux ou de factures.
Tu fais attention au ton (respectueux, neutre, professionnel).
""",
}

BASE_SYSTEM_PROMPT = """
Tu es une IA de conversation s√©rieuse, respectueuse, jamais offensante.
Interdiction de produire des propos haineux, discriminants, violents
ou ill√©gaux. Tu refuses toute demande dangereuse.

Style :
- phrases assez courtes,
- explications claires, structur√©es,
- vocabulaire simple, adapt√© √† un agriculteur ou √† un professionnel,
- tu raisonnes r√©ellement avant de r√©pondre (pas de r√©ponses al√©atoires),
- tu expliques tes √©tapes de r√©flexion de mani√®re r√©sum√©e.
"""

# =========================================================
# FONCTIONS OUTILS
# =========================================================

def lire_csv(file) -> str:
    """R√©sum√© texte d'un CSV pour donner du contexte √† l'IA."""
    try:
        df = pd.read_csv(file)
    except Exception:
        file.seek(0)
        df = pd.read_csv(file, sep=";")
    apercu = df.head(10)
    return (
        f"Fichier CSV : {getattr(file, 'name', 'inconnu')}\n"
        f"Colonnes : {list(df.columns)}\n"
        f"Extrait (10 lignes) :\n{apercu.to_markdown(index=False)}"
    )


def lire_pdf(file) -> str:
    """Extrait les 2 premi√®res pages d'un PDF pour le contexte IA."""
    texte_total = []
    with pdfplumber.open(file) as pdf:
        for i, page in enumerate(pdf.pages):
            if i >= 2:
                break
            texte_page = page.extract_text() or ""
            texte_total.append(f"--- Page {i+1} ---\n{texte_page}")
    return (
        f"Fichier PDF : {getattr(file, 'name', 'inconnu')}\n"
        "Extraits des 2 premi√®res pages :\n" + "\n\n".join(texte_total)
    )


def generer_modele_facture_df():
    """Mod√®le simple de facture (agricole ou autre)."""
    return pd.DataFrame({
        "Date": [""],
        "N¬∞ facture": [""],
        "Client": [""],
        "Adresse client": [""],
        "SIRET / TVA client": [""],
        "Description": [""],
        "Quantit√©": [0],
        "Unit√©": [""],
        "Prix unitaire HT": [0.0],
        "TVA (%)": [20],
        "Total HT": [0.0],
        "Total TTC": [0.0],
        "Mode de r√®glement": [""],
        "Date d‚Äô√©ch√©ance": [""],
    })


def generer_modeles_tableaux_gestion():
    """Mod√®les de tableaux utiles pour une ferme."""
    df_marges = pd.DataFrame(columns=[
        "Ann√©e", "Atelier / Culture", "Surface_ha / Nb t√™tes",
        "Produit total ‚Ç¨", "Charges op√©rationnelles ‚Ç¨",
        "Charges de structure ‚Ç¨", "Marge brute ‚Ç¨", "EBE ‚Ç¨",
        "Marge brute /ha ou /t√™te", "EBE /ha ou /t√™te"
    ])

    df_tresorerie = pd.DataFrame(columns=[
        "Date", "Type (encaissement / d√©caissement)", "Cat√©gorie",
        "Libell√©", "Montant ‚Ç¨", "Moyen de paiement", "Atelier", "Observation"
    ])

    df_elevage = pd.DataFrame(columns=[
        "Ann√©e", "Esp√®ce", "Atelier", "Nb animaux moyen",
        "GMQ (g/j) ou Prod. lait (kg/VL/an)",
        "Conso concentr√©s (kg/an)", "Taux de renouvellement (%)",
        "Taux de mortalit√© (%)", "Remarques techniques"
    ])

    return {
        "Suivi_marges": df_marges,
        "Tr√©sorerie": df_tresorerie,
        "Elevage": df_elevage,
    }


def get_meteo_precise(location: str, nb_villes: int = 5):
    """
    M√©t√©o pr√©cise via Open-Meteo :
    - cherche plusieurs villes proches,
    - renvoie la m√©t√©o d√©taill√©e pour la premi√®re
      + la liste des villes trouv√©es.
    """
    if not location:
        return None, None, "Aucune localisation fournie."

    try:
        geo_url = "https://geocoding-api.open-meteo.com/v1/search"
        params_geo = {
            "name": location,
            "count": nb_villes,
            "language": "fr",
            "format": "json",
        }
        r_geo = requests.get(geo_url, params=params_geo, timeout=8)
        if r_geo.status_code != 200:
            return None, None, "Impossible de joindre le service de g√©ocodage m√©t√©o."

        data_geo = r_geo.json()
        if "results" not in data_geo or not data_geo["results"]:
            return None, None, f"Aucune ville trouv√©e pour ¬´ {location} ¬ª."

        villes = pd.DataFrame([{
            "Nom": r["name"],
            "Pays": r.get("country", ""),
            "Lat": r["latitude"],
            "Lon": r["longitude"],
        } for r in data_geo["results"]])

        loc = data_geo["results"][0]
        lat = loc["latitude"]
        lon = loc["longitude"]
        nom = loc.get("name", location)
        pays = loc.get("country", "")

        meteo_url = "https://api.open-meteo.com/v1/forecast"
        params_met = {
            "latitude": lat,
            "longitude": lon,
            "hourly": "temperature_2m,precipitation",
            "daily": "temperature_2m_max,temperature_2m_min,precipitation_sum",
            "current_weather": "true",
            "timezone": "auto",
        }
        r_met = requests.get(meteo_url, params=params_met, timeout=8)
        if r_met.status_code != 200:
            return None, villes, "Impossible de joindre le service m√©t√©o."

        data_met = r_met.json()
        current = data_met.get("current_weather", {})
        daily = data_met.get("daily", {})

        df_daily = None
        try:
            df_daily = pd.DataFrame({
                "Date": daily["time"],
                "T max (¬∞C)": daily["temperature_2m_max"],
                "T min (¬∞C)": daily["temperature_2m_min"],
                "Pluie jour (mm)": daily["precipitation_sum"],
            })
        except Exception:
            pass

        info = {
            "nom": nom,
            "pays": pays,
            "current": current,
            "daily_df": df_daily,
        }
        return info, villes, None
    except Exception as e:
        return None, None, f"Erreur m√©t√©o : {e}"


# =========================================================
# √âTAT DE SESSION : une seule conversation principale
# =========================================================

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Bonjour üëã\n\nJe suis ton IA conseill√®re. Explique-moi ta situation ou ta question."}
    ]

if "file_context" not in st.session_state:
    st.session_state.file_context = []  # extraits de fichiers


# =========================================================
# SIDEBAR : r√©glages globaux
# =========================================================

with st.sidebar:
    st.markdown("### ‚öôÔ∏è R√©glages du chat")
    st.caption(f"Version {APP_VERSION}")

    langue = st.selectbox("Langue de r√©ponse :", list(LANG_OPTIONS.keys()), index=0)
    mode = st.selectbox("Mode :", list(MODE_PROMPTS.keys()), index=1)
    modele_label = st.selectbox("Mod√®le IA :", list(MODEL_OPTIONS.keys()), index=0)

    if st.button("üîÑ R√©initialiser la discussion"):
        st.session_state.messages = [
            {"role": "assistant", "content": "Nouvelle discussion. Explique-moi ta situation."}
        ]
        st.session_state.file_context = []
        st.experimental_rerun()

    st.markdown("---")
    st.markdown(
        "L‚ÄôIA utilise **Groq** (mod√®les LLaMA) : rapide et pr√©cis.\n\n"
        "Tu peux d√©poser des fichiers et demander de l‚Äôaide sur les chiffres ou les papiers."
    )

# =========================================================
# FONCTION : construire messages pour l‚ÄôIA
# =========================================================

def construire_messages():
    lang_code = LANG_OPTIONS.get(langue, "fr")
    mode_prompt = MODE_PROMPTS.get(mode, "")

    messages = [
        {"role": "system", "content": BASE_SYSTEM_PROMPT},
        {"role": "system", "content": f"R√©ponds en langue : {langue} (code {lang_code})."},
        {"role": "system", "content": mode_prompt},
    ]

    if st.session_state.file_context:
        contexte_text = (
            "Voici des extraits de documents fournis par l‚Äôutilisateur "
            "(tableaux, PDF, etc.). Utilise-les si c‚Äôest utile :\n\n"
            + "\n\n---\n\n".join(st.session_state.file_context[-3:])
        )
        messages.append({"role": "system", "content": contexte_text})

    dernier_messages = st.session_state.messages[-10:]
    for m in dernier_messages:
        if m["role"] in ("user", "assistant"):
            messages.append({"role": m["role"], "content": m["content"]})

    return messages


def appeler_groq():
    if client is None:
        return (
            "‚ùå Je ne peux pas r√©pondre pour l‚Äôinstant.\n\n"
            "La cl√© `GROQ_API_KEY` n'est pas configur√©e dans les *Secrets* Streamlit."
        )

    model_conf = MODEL_OPTIONS[modele_label]
    msgs = construire_messages()

    try:
        completion = client.chat.completions.create(
            model=model_conf["id"],
            messages=msgs,
            temperature=model_conf["temp"],
            max_tokens=model_conf["max_tokens"],
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"‚ùå Erreur lors de l'appel au mod√®le Groq : {e}"


# =========================================================
# HEADER
# =========================================================

st.markdown("<div class='app-title'>üí¨ IA Conseiller ‚Äì Chat s√©rieux</div>", unsafe_allow_html=True)
st.markdown(
    "<div class='app-subtitle'>Une seule interface pour discuter, analyser tes chiffres, t'aider sur les papiers et la m√©t√©o.</div>",
    unsafe_allow_html=True,
)
st.markdown("---")

# =========================================================
# AFFICHAGE DE LA CONVERSATION
# =========================================================

for message in st.session_state.messages:
    with st.chat_message("assistant" if message["role"] == "assistant" else "user"):
        st.markdown(message["content"])

# Champ de saisie
user_input = st.chat_input("√âcris ta question ou ta situation ici‚Ä¶")

if user_input:
    texte = user_input.strip()
    if texte:
        st.session_state.messages.append({"role": "user", "content": texte})
        with st.chat_message("user"):
            st.markdown(texte)

        with st.chat_message("assistant"):
            placeholder = st.empty()
            placeholder.markdown("Je r√©fl√©chis √† ta situation‚Ä¶")
            answer = appeler_groq()
            placeholder.markdown(answer)

        st.session_state.messages.append({"role": "assistant", "content": answer})

# =========================================================
# OUTILS : fichiers, factures, tableaux, m√©t√©o
# =========================================================

st.markdown("---")
st.markdown("### üß∞ Outils pratiques (optionnel)")

with st.expander("üìÇ Fichiers (PDF / CSV) √† analyser", expanded=False):
    uploaded_files = st.file_uploader(
        "D√©pose ici tes dossiers, tableaux, relev√©s (PDF ou CSV) :",
        type=["pdf", "csv"],
        accept_multiple_files=True,
    )

    if uploaded_files and st.button("Analyser les fichiers"):
        resumes = []
        for f in uploaded_files:
            try:
                data = f.read()
                if f.name.lower().endswith(".csv"):
                    resume = lire_csv(io.BytesIO(data))
                else:
                    resume = lire_pdf(io.BytesIO(data))
                resumes.append(resume)
            except Exception as e:
                resumes.append(f"Impossible de lire le fichier {f.name} : {e}")

        st.session_state.file_context.extend(resumes)
        st.success("Fichiers analys√©s. L‚ÄôIA en tiendra compte dans ses prochaines r√©ponses.")
        for r in resumes:
            st.code(r[:1200])

with st.expander("üßæ Mod√®les de factures & tableaux de gestion", expanded=False):
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üßæ Mod√®le de facture"):
            df_fact = generer_modele_facture_df()
            st.dataframe(df_fact, use_container_width=True)
            csv_fact = df_fact.to_csv(index=False).encode("utf-8")
            st.download_button(
                "üì• T√©l√©charger facture.csv",
                data=csv_fact,
                file_name="modele_facture.csv",
                mime="text/csv",
                use_container_width=True,
            )
    with col2:
        if st.button("üìä Mod√®les de tableaux de gestion"):
            modeles = generer_modeles_tableaux_gestion()
            for nom, df_mod in modeles.items():
                st.markdown(f"**{nom}**")
                st.dataframe(df_mod, use_container_width=True)
                csv_mod = df_mod.to_csv(index=False).encode("utf-8")
                st.download_button(
                    f"üì• T√©l√©charger {nom}.csv",
                    data=csv_mod,
                    file_name=f"{nom}.csv",
                    mime="text/csv",
                    use_container_width=True,
                )

with st.expander("üå¶Ô∏è M√©t√©o tr√®s pr√©cise (plusieurs villes)", expanded=False):
    loc = st.text_input("Ville / commune :", placeholder="Ex : Lisieux, Alen√ßon, Limoges‚Ä¶")
    if st.button("Voir la m√©t√©o"):
        info, villes_df, err = get_meteo_precise(loc)
        if err:
            st.error(err)
        else:
            if villes_df is not None and not villes_df.empty:
                st.markdown("**Villes trouv√©es :**")
                st.dataframe(villes_df, use_container_width=True)

            if info is None:
                st.error("Impossible de r√©cup√©rer la m√©t√©o d√©taill√©e.")
            else:
                st.success(f"M√©t√©o pour {info['nom']} ({info['pays']})")
                current = info.get("current", {})
                if current:
                    c1, c2, c3 = st.columns(3)
                    with c1:
                        st.metric("Temp√©rature (¬∞C)", current.get("temperature", "NA"))
                    with c2:
                        st.metric("Vent (km/h)", current.get("windspeed", "NA"))
                    with c3:
                        st.metric("Code m√©t√©o", current.get("weathercode", "NA"))

                df_daily = info.get("daily_df")
                if df_daily is not None:
                    st.markdown("**Pr√©visions 5 jours :**")
                    st.dataframe(df_daily.head(5), use_container_width=True)
                    st.caption(
                        "Source : Open-Meteo. Pour les d√©cisions sensibles "
                        "(r√©colte, traitements), croise avec une appli m√©t√©o locale."
                    )
