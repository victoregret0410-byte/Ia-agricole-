import streamlit as st
from groq import Groq
import pandas as pd
import pdfplumber
import io
import requests
import os

# =========================================================
# CONFIG GLOBALE
# =========================================================

APP_NAME = "üåæ IA agricole ‚Äì Chat rapide"
APP_VERSION = "6.0.0"

st.set_page_config(
    page_title=APP_NAME,
    page_icon="üåæ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Client Groq (cl√© dans les secrets Streamlit : GROQ_API_KEY)
client = Groq(api_key=os.getenv("GROQ_API_KEY", ""))


# =========================================================
# SYSTEM PROMPT (CERVEAU G√âN√âRAL)
# =========================================================

BASE_SYSTEM_PROMPT = """
Tu es un conseiller agricole IA francophone, bienveillant, jamais offensant.
Tu aides les agriculteurs √† :
- mieux g√©rer leurs cultures, prairies, √©levage (bovin, ovin, caprin, porc, volaille‚Ä¶),
- r√©fl√©chir √† leur organisation de travail,
- comprendre leurs chiffres (produits, charges, marges, EBE‚Ä¶),
- gagner du temps sur les papiers (factures, tableaux, relev√©s‚Ä¶),
- penser leurs investissements avec prudence (sans faire de conseil financier risqu√©).

Style :
- fran√ßais simple, ton humain, sans jugement,
- phrases courtes, claires, concr√®tes,
- tu expliques comme √† un coll√®gue agriculteur,
- tu utilises quelques emojis pour structurer (üåæüêÑüìäüí∂üí°‚ö†Ô∏è‚úÖ‚Ä¶),
- tu restes toujours respectueux, jamais offensant.
"""

# =========================================================
# STYLE GLOBAL
# =========================================================

st.markdown(
    """
    <style>
    html, body, [class*="css"] {
        font-family: -apple-system, BlinkMacSystemFont, system-ui, sans-serif;
    }
    body {
        background-color: #f5f7fb;
    }
    .main {
        background: #f5f7fb;
    }
    .stButton>button, .stDownloadButton>button {
        border-radius: 999px;
        padding: 0.35rem 1.2rem;
        font-weight: 600;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# =========================================================
# FONCTIONS UTILITAIRES
# =========================================================

def lire_csv(file) -> str:
    """R√©sum√© texte d'un CSV pour le contexte IA (10 lignes max)."""
    try:
        df = pd.read_csv(file)
    except Exception:
        file.seek(0)
        df = pd.read_csv(file, sep=";")
    apercu = df.head(10)
    return (
        f"Fichier CSV : {getattr(file, 'name', 'inconnu')}\n"
        f"Colonnes : {list(df.columns)}\n"
        f"Extrait (10 lignes) :\n{apercu.to_markdown(index=False)}"
    )


def lire_pdf(file) -> str:
    """Extrait les 2 premi√®res pages d'un PDF pour le contexte IA."""
    texte_total = []
    with pdfplumber.open(file) as pdf:
        for i, page in enumerate(pdf.pages):
            if i >= 2:
                break
            texte_page = page.extract_text() or ""
            texte_total.append(f"--- Page {i+1} ---\n{texte_page}")
    return (
        f"Fichier PDF : {getattr(file, 'name', 'inconnu')}\n"
        "Extraits des 2 premi√®res pages :\n" + "\n\n".join(texte_total)
    )


def generer_modele_facture_df():
    """Mod√®le simple de facture agricole."""
    return pd.DataFrame({
        "Date": [""],
        "N¬∞ facture": [""],
        "Client": [""],
        "Adresse client": [""],
        "SIRET client": [""],
        "Description": [""],
        "Quantit√©": [0],
        "Unit√©": [""],  # t, kg, h, u...
        "Prix unitaire HT": [0.0],
        "TVA (%)": [20],
        "Total HT": [0.0],
        "Total TTC": [0.0],
        "Mode de r√®glement": [""],
        "Date d‚Äô√©ch√©ance": [""],
    })


def generer_modeles_tableaux_gestion():
    """Quelques mod√®les de tableaux utiles (marges, tr√©sorerie, √©levage)."""
    df_marges = pd.DataFrame(columns=[
        "Ann√©e", "Atelier / Culture", "Surface_ha / Nb t√™tes",
        "Produit total ‚Ç¨", "Charges op√©rationnelles ‚Ç¨",
        "Charges de structure ‚Ç¨", "Marge brute ‚Ç¨", "EBE ‚Ç¨",
        "Marge brute /ha ou /t√™te", "EBE /ha ou /t√™te"
    ])

    df_tresorerie = pd.DataFrame(columns=[
        "Date", "Type", "Cat√©gorie", "Libell√©",
        "Montant ‚Ç¨", "Sens",
        "Moyen de paiement", "Atelier", "Observation"
    ])

    df_elevage = pd.DataFrame(columns=[
        "Ann√©e", "Esp√®ce", "Atelier", "Nb animaux moyen",
        "GMQ (g/j) ou Prod. lait (kg/VL/an)",
        "IC / conso concentr√©s (kg/an)", "Taux de renouvellement (%)",
        "Taux de mortalit√© (%)", "Remarques techniques"
    ])

    return {
        "Suivi_marges": df_marges,
        "Tr√©sorerie": df_tresorerie,
        "Elevage": df_elevage
    }


def texte_idees_schemas():
    return (
        "üìà **Id√©es de sch√©mas pour organiser la ferme**\n\n"
        "1Ô∏è‚É£ Rotation des cultures\n"
        "2Ô∏è‚É£ Organisation du travail (quotidien / hebdo / saison)\n"
        "3Ô∏è‚É£ Flux en b√¢timent (entr√©e ‚Üí zones ‚Üí sortie)\n\n"
        "Tu peux les dessiner sur papier ou dans Canva/PowerPoint."
    )


def get_meteo(location: str):
    """Mini m√©t√©o via Open-Meteo."""
    if not location:
        return None, "Aucune localisation fournie."
    try:
        geo_url = "https://geocoding-api.open-meteo.com/v1/search"
        params_geo = {
            "name": location,
            "count": 1,
            "language": "fr",
            "format": "json"
        }
        r_geo = requests.get(geo_url, params=params_geo, timeout=8)
        if r_geo.status_code != 200:
            return None, "Impossible de joindre le service de g√©ocodage m√©t√©o."

        data_geo = r_geo.json()
        if "results" not in data_geo or not data_geo["results"]:
            return None, f"Aucune localisation trouv√©e pour '{location}'."

        loc = data_geo["results"][0]
        lat = loc["latitude"]
        lon = loc["longitude"]
        nom = loc.get("name", location)
        pays = loc.get("country", "")

        meteo_url = "https://api.open-meteo.com/v1/forecast"
        params_met = {
            "latitude": lat,
            "longitude": lon,
            "hourly": "temperature_2m,precipitation",
            "daily": "temperature_2m_max,temperature_2m_min,precipitation_sum",
            "current_weather": "true",
            "timezone": "auto"
        }
        r_met = requests.get(meteo_url, params=params_met, timeout=8)
        if r_met.status_code != 200:
            return None, "Impossible de joindre le service m√©t√©o."

        data_met = r_met.json()
        current = data_met.get("current_weather", {})
        daily = data_met.get("daily", {})

        df_daily = None
        try:
            df_daily = pd.DataFrame({
                "Date": daily["time"],
                "T max (¬∞C)": daily["temperature_2m_max"],
                "T min (¬∞C)": daily["temperature_2m_min"],
                "Pluie jour (mm)": daily["precipitation_sum"],
            })
        except Exception:
            pass

        info = {
            "nom": nom,
            "pays": pays,
            "current": current,
            "daily_df": df_daily
        }
        return info, None
    except Exception as e:
        return None, f"Erreur m√©t√©o : {e}"


# =========================================================
# √âTAT : MULTI CONVERSATIONS (COMME CHATGPT)
# =========================================================

if "conversations" not in st.session_state:
    st.session_state.conversations = []  # liste de dict
if "current_conv_index" not in st.session_state:
    st.session_state.current_conv_index = 0


def creer_nouvelle_conversation(style: str = "general"):
    """Cr√©e une nouvelle discussion avec un type (g√©n√©ral, √©levage, compta)."""
    if style == "elevage":
        titre = f"√âlevage {len(st.session_state.conversations) + 1}"
        intro = (
            "On se concentre sur **l‚Äô√©levage** (bovins, ovins, caprins, volailles‚Ä¶).\n\n"
            "Tu peux me parler de rations, b√¢timents, reproduction, sant√©, organisation‚Ä¶"
        )
    elif style == "compta":
        titre = f"Compta {len(st.session_state.conversations) + 1}"
        intro = (
            "On se concentre sur **la gestion / compta** üìäüí∂.\n\n"
            "Donne-moi tes produits, charges, annuit√©s‚Ä¶ je t‚Äôaide √† les lire et analyser."
        )
    else:
        style = "general"
        titre = f"Discussion {len(st.session_state.conversations) + 1}"
        intro = (
            "Salut üëã\n\n"
            "Tu peux me parler de ta ferme, de tes cultures, de ton √©levage, "
            "de ton organisation ou de tes papiers. On regarde √ßa calmement."
        )

    conv = {
        "title": titre,
        "type": style,  # general / elevage / compta
        "messages": [
            {"role": "assistant", "content": intro},
        ],
        "fichiers_contextes": [],
    }
    st.session_state.conversations.append(conv)
    st.session_state.current_conv_index = len(st.session_state.conversations) - 1


# Premi√®re conversation au d√©marrage
if not st.session_state.conversations:
    creer_nouvelle_conversation("general")


# =========================================================
# BARRE LAT√âRALE (LISTE DES CHATS)
# =========================================================

with st.sidebar:
    st.markdown("### üåæ IA agricole ‚Äì Chats")
    st.caption(f"Version {APP_VERSION}")

    st.markdown("#### ‚ûï Nouvelle discussion")
    c_new1, c_new2, c_new3 = st.columns(3)
    with c_new1:
        if st.button("G√©n√©ral"):
            creer_nouvelle_conversation("general")
    with c_new2:
        if st.button("√âlevage"):
            creer_nouvelle_conversation("elevage")
    with c_new3:
        if st.button("Compta"):
            creer_nouvelle_conversation("compta")

    st.markdown("---")

    labels = [conv["title"] for conv in st.session_state.conversations]
    idx = st.session_state.current_conv_index
    if idx >= len(labels):
        idx = len(labels) - 1

    selected = st.radio(
        "Mes discussions",
        options=list(range(len(labels))),
        format_func=lambda i: labels[i],
        index=idx,
    )
    st.session_state.current_conv_index = selected

    st.markdown("---")
    st.markdown(
        "**üí° Astuce :** une discussion = un sujet (√©levage, compta, projet‚Ä¶).\n"
        "Tu peux en cr√©er plusieurs et revenir dessus."
    )


# Conversation courante
conv = st.session_state.conversations[st.session_state.current_conv_index]


# =========================================================
# COULEURS SELON TYPE DE DISCUSSION
# =========================================================

def couleurs_par_type(t: str):
    if t == "elevage":
        return "#e4f5e9", "#f6fffa", "#ffffff", "#2e7d32"
    if t == "compta":
        return "#e3f2fd", "#f5fbff", "#ffffff", "#1565c0"
    # g√©n√©ral
    return "#fff7e3", "#fffdf7", "#ffffff", "#d7961b"


grad_start, grad_mid, grad_end, accent = couleurs_par_type(conv.get("type", "general"))

st.markdown(
    f"""
    <style>
    .block-container {{
        background: linear-gradient(
            135deg,
            {grad_start} 0%,
            {grad_mid} 55%,
            {grad_end} 100%
        );
        padding-top: 1.2rem;
        padding-bottom: 3rem;
    }}
    h1, h2, h3, h4 {{
        color: {accent};
    }}
    </style>
    """,
    unsafe_allow_html=True,
)


# =========================================================
# FONCTION POUR CONSTRUIRE LES MESSAGES (RAPIDE)
# =========================================================

def construire_messages_pour_ia(conv, style_reponse: str):
    """
    Pour aller vite : on envoie seulement :
    - le system prompt,
    - les 8 derniers messages de la conversation,
    - les 2 derniers contextes fichiers (si pr√©sents),
    + une consigne de style.
    """
    messages = [{"role": "system", "content": BASE_SYSTEM_PROMPT}]

    # on prend seulement les 8 derniers messages
    derniers = conv["messages"][-8:]
    for m in derniers:
        role = m["role"]
        if role not in ["user", "assistant"]:
            continue
        messages.append({"role": role, "content": m["content"]})

    # style de r√©ponse
    if style_reponse == "Rapide et synth√©tique":
        messages.append({
            "role": "system",
            "content": "R√©ponds de fa√ßon claire, concr√®te et assez courte (2 √† 4 paragraphes max)."
        })
    else:
        messages.append({
            "role": "system",
            "content": "Tu peux donner un peu plus de d√©tails, tout en restant simple et structur√©."
        })

    # contexte fichiers : seulement les 2 derniers
    if conv["fichiers_contextes"]:
        ctx = conv["fichiers_contextes"][-2:]
        contexte_text = (
            "Voici des extraits de fichiers fournis par l‚Äôagriculteur "
            "(tableaux, PDF, etc.). Utilise ce contexte si utile :\n\n"
            + "\n\n---\n\n".join(ctx)
        )
        messages.append({"role": "system", "content": contexte_text})

    return messages


# =========================================================
# LAYOUT PRINCIPAL : CHAT + OUTILS (UNE SEULE PAGE)
# =========================================================

col_chat, col_tools = st.columns([2.4, 1.6])

# ------------------ COLONNE GAUCHE : CHAT ------------------
with col_chat:
    st.title("üí¨ Chat IA agricole")

    style_reponse = st.radio(
        "Style de r√©ponse :",
        options=["Rapide et synth√©tique", "Un peu plus d√©taill√©e"],
        horizontal=True,
    )

    st.markdown("---")

    # Afficher l'historique
    for msg in conv["messages"]:
        with st.chat_message("assistant" if msg["role"] == "assistant" else "user"):
            st.markdown(msg["content"])

    # Champ de saisie
    user_input = st.chat_input("√âcris ta question ou ton probl√®me ici‚Ä¶")

    if user_input:
        user_input = user_input.strip()
        conv["messages"].append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        messages_for_api = construire_messages_pour_ia(conv, style_reponse)

        # Appel mod√®le ultra rapide : Groq / llama-3.1-8b-instant
        with st.chat_message("assistant"):
            placeholder = st.empty()
            placeholder.markdown("Je r√©fl√©chis √† ta situation‚Ä¶ ‚è≥")

            try:
                completion = client.chat.completions.create(
                    model="llama-3.1-8b-instant",
                    messages=messages_for_api,
                    temperature=0.3,
                    max_tokens=400,
                )
                answer = completion.choices[0].message.content
            except Exception as e:
                msg = str(e)
                if "invalid_api_key" in msg or "authentication" in msg.lower():
                    answer = (
                        "‚ùå Je ne peux pas r√©pondre car la **cl√© GROQ_API_KEY** n‚Äôest pas valide.\n\n"
                        "‚û°Ô∏è Va dans les *Secrets* Streamlit et v√©rifie que tu as bien :\n"
                        "`GROQ_API_KEY = \"ta_cle_groq_ici\"`.\n"
                    )
                else:
                    answer = (
                        "‚ùå Impossible de contacter le mod√®le Groq pour l‚Äôinstant.\n\n"
                        "V√©rifie ta connexion internet et ta cl√© `GROQ_API_KEY`.\n\n"
                        f"(D√©tail technique : {e})"
                    )

            placeholder.markdown(answer)

        conv["messages"].append({"role": "assistant", "content": answer})

    # Sauvegarde
    st.session_state.conversations[st.session_state.current_conv_index] = conv


# ------------------ COLONNE DROITE : OUTILS ------------------
with col_tools:
    st.markdown("### üìÇ Fichiers & outils")

    uploaded_files = st.file_uploader(
        "D√©pose ici tes PDF ou CSV (dossiers, marges, factures...).",
        type=["csv", "pdf"],
        accept_multiple_files=True,
    )

    if uploaded_files and st.button("‚úÖ Analyser les fichiers"):
        resumes = []
        for f in uploaded_files:
            try:
                data = f.read()
                if f.name.lower().endswith(".csv"):
                    resume = lire_csv(io.BytesIO(data))
                else:
                    resume = lire_pdf(io.BytesIO(data))
                resumes.append(resume)
            except Exception as e:
                resumes.append(f"Impossible de lire le fichier {f.name} : {e}")

        conv["fichiers_contextes"].extend(resumes)
        st.session_state.conversations[st.session_state.current_conv_index] = conv
        st.success("Fichiers analys√©s. L‚ÄôIA tiendra compte de ces
